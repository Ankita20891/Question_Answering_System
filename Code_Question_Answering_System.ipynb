{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Question Answering System Using COVID-19 Article</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import nltk, re, json, string, spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question and Answering (QA) System\n",
    "\n",
    "Developed a QA system which allow you to search for answers in an article. For example, the file `qa.json` contains a research article. This article can answer a number of questions about COVID-19. You will design a solution to automatically search answers to these questions in this article.\n",
    "\n",
    "`qa.json` is taken from https://github.com/deepset-ai/COVID-QA. This file contains a few questions, and answers to these questions have been located in the article. Let's define a QA system and check if your system can locate the right answers.\n",
    "\n",
    "The following script helps you understand `qa.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDC Summary 21 MAR 2020,\n",
      "https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/summary.html\n",
      "\n",
      "This is a rapidly evolving situation and CDC will provide updated information and guidance as it becomes \n"
     ]
    }
   ],
   "source": [
    "# Retrieve the article\n",
    "\n",
    "data = json.load(open(\"qa.json\",\"r\"))\n",
    "article = data[\"context\"]\n",
    "\n",
    "# A long article. Just print the first 200 characters\n",
    "print(article[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What age group has the highest rate of severe outcomes?', 'id': 236, 'answers': [{'text': 'people 85 years and older', 'answer_start': 6117}], 'is_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What age group has the highest rate of severe outcomes?',\n",
       " 'How is COVID-19 spread?',\n",
       " 'How many states in the U.S. have reported cases of COVID-19?',\n",
       " 'When did the White House launch the \"15 Days to Slow the Spread\" program?',\n",
       " 'What should mildly-ill patients do?',\n",
       " 'What type of virus is SARS-CoV-2?',\n",
       " 'What viruses are similar to the COVID-19 coronavirus?',\n",
       " 'What are the phases of a pandemic?',\n",
       " 'At which phase does the peak of the pandemic occur?',\n",
       " 'People with which medical conditions have a higher rate of severe illness?',\n",
       " 'What kind of test can diagnose COVID-19?',\n",
       " 'In what species did the COVID-19 virus likely originate?',\n",
       " 'What risk factors should be considered in addition to clinical symptoms?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve all the questions and answers\n",
    "qas = data[\"qas\"]\n",
    "\n",
    "# show the first question-answer pair. Note the answer starts at the 6117th character\n",
    "print(qas[0])\n",
    "\n",
    "# get all questions\n",
    "qs = [item[\"question\"] for item in qas]\n",
    "qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, following the instructions below step by step to develop the QA system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Tokenizer\n",
    "\n",
    "Define a function `tokenize(doc)`  as follows:\n",
    "   - Take a piece of text (i.e. variable `doc`) as an input\n",
    "   - Split the input text into unigrams\n",
    "   - Clean up tokens as follows:\n",
    "       - Lemmatize all unigrams\n",
    "       - Remove all stop words\n",
    "       - Remove all punctuations\n",
    "       - Convert all unigrams to the lower case \n",
    "       - remove empty unigrams\n",
    "   - Return the list of unigrams after all the processing. (Hint: you can use spacy package for this task. To test if a token is stop word or punctuation, check https://spacy.io/api/token#attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "def tokenize(doc):\n",
    "    doc = nlp(doc)\n",
    "    tokens = []\n",
    "    \n",
    "    # add your code\n",
    "    #create unigrams and lemmatize\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    #remove stop words and punctuation\n",
    "    stop_words = stopwords.words('english')\n",
    "    punctuations = string.punctuation+'—'\n",
    "    \n",
    "    tokens = [ token.lower() for token in tokens if token not in stop_words and token not in punctuations]\n",
    "    \n",
    "    #remove empty space\n",
    "    tokens = [token.strip() for token in tokens if token.strip()!='']\n",
    "    \n",
    "    #return tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old', 'people', 'people', 'age', 'severe', 'chronic', 'medical', 'condition', 'like', 'heart', 'disease', 'lung', 'disease', 'diabetes', 'example', 'seem', 'high', 'risk', 'develop', 'serious', 'covid-19', 'illness']\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "doc = 'Older people and people of all ages with severe chronic medical conditions — \\\n",
    "like heart disease, lung disease and diabetes, \\\n",
    "for example — seem to be at higher risk of developing serious COVID-19 illness.'\n",
    "\n",
    "print(tokenize(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing TF-IDF Matrix\n",
    "\n",
    "Define a function `compute_tf_idf(docs)` as follows: \n",
    "\n",
    "- Take `docs`, a list of documents (e.g. a list of questions) as an input\n",
    "- Tokenize each document in `docs` using the `tokenize` function defined in Q3.1. \n",
    "- Calculate tf_idf weights as shown in lecture notes (Hint: you can reuse the last code segment in NLP Lecture Notes (II))\n",
    "- Return a smoothed normalized `tf_idf` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "def compute_tfidf(docs):\n",
    "    \n",
    "    smoothed_tf_idf = None\n",
    "    \n",
    "     # add your code here\n",
    "    \n",
    "    # Step 1. and Step 2. get tokens of each document as list (Call function Q.3.1) \n",
    "    # process all documents to get list of token list\n",
    "    docs_tokens={idx:tokenize(doc) and nltk.FreqDist(tokenize(doc)) for idx,doc in enumerate(docs)}\n",
    "    #print(docs_tokens)\n",
    "    # step 3. get document-term matrix\n",
    "    dtm=pd.DataFrame.from_dict(docs_tokens, orient=\"index\")\n",
    "    dtm\n",
    "    dtm=dtm.fillna(0)\n",
    "    dtm\n",
    "    dtm = dtm.sort_index(axis = 0)\n",
    "    #print(dtm)\n",
    "    # step 4. get normalized term frequency (tf) matrix        \n",
    "    tf=dtm.values\n",
    "    doc_len=tf.sum(axis=1, keepdims=True)\n",
    "    tf=np.divide(tf, doc_len)\n",
    "    #print(tf)\n",
    "    # step 5. get idf\n",
    "    df=np.where(tf>0,1,0)\n",
    "    idf=np.log(np.divide(len(docs), np.sum(df, axis=0)))+1\n",
    "    #print(idf)\n",
    "    smoothed_idf=np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1   \n",
    "    # get tf-idf\n",
    "    tf_idf=normalize(tf*idf)\n",
    "    tf_idf\n",
    "    smoothed_tf_idf=normalize(tf*smoothed_idf)\n",
    "    \n",
    "    #return smoothed_tf_idf\n",
    "    return smoothed_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41, 0.41, 0.41, 0.41, 0.41, 0.41, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.61, 0.8 , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.42, 0.42, 0.42,\n",
       "        0.42, 0.42]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function using three questions\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "compute_tfidf(qs[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puting Everything Together\n",
    "\n",
    "Define a function `find_solutions(qs, article)` as follows: \n",
    "\n",
    "- Take two inputs:\n",
    "    - `qs`: a list of questions (i.e. strings)\n",
    "    - `article`: a document which may contain answers to the questions\n",
    "- Segment the article into sentences (i.e. `sents`). You will locate the sentence which can answer a question.\n",
    "- Concatenate the questions (`qs`) and sentences (`sents`) into a single list (i.e. `qs + sents`)\n",
    "- Call the function `compute_tfidf` defined in Q3.2 with `qs + sents` to get a `TF-IDF` matrix. (Note, now `qs` and `sents` are converted to TF-IDF vectors in the same dimension. As a result, you can measure their similarities.) \n",
    "- Split the `TF-IDF` matrix into two sub matrices, one corresponding to `qs` and the other for `sents`. \n",
    "- Next, calculate the pairwise cosine similarity between the `qs` and `sents`. With $m$ questions and $n$ sentences, you should get a $m \\times n$ matrix. (hint: you can `sklearn.metrics.pairwise_distances` to calculate pairwise distances between two matrices)\n",
    "- Finally, the answer to each question is the sentence which has the `maximum similarity` to it. \n",
    "- Print out each question and its matched answer. Check if your QA system is able to find the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "def find_solutions(qs, doc):\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    #segment article into sentences\n",
    "    sents = nltk.sent_tokenize(doc)\n",
    "    #len(sents)\n",
    "    #type(sents)\n",
    "    #sents\n",
    "    \n",
    "    #concatenatethe questions(qs) and sentences(sents) into a simple list i.e.(qs + sents)\n",
    "    simple_list = qs + sents\n",
    "    #print(simple_list)\n",
    "    \n",
    "    #call commute_TFIDF defined in Q.3. with qs + sents to get a matrix\n",
    "    tfidf_matrix = compute_tfidf(simple_list)\n",
    "    print(tfidf_matrix)\n",
    "    print(tfidf_matrix.shape)\n",
    "    \n",
    "    #splitthe tfidf matrix into two sub matrices\n",
    "    Q = tfidf_matrix[:len(qs),0:]\n",
    "    #print(Q)\n",
    "    #print(Q.shape)\n",
    "    \n",
    "    A = tfidf_matrix[len(qs):,0:]\n",
    "    #print(A)\n",
    "    #print(A.shape)\n",
    "    \n",
    "    #pairwise cosine similarity\n",
    "    # calculate cosince distance of every pair of documents similarity is 1-distance\n",
    "    similarity=1-pairwise_distances(Q, A, metric = 'cosine')\n",
    "    #print(similarity)\n",
    "    #print(similarity.shape)\n",
    "    \n",
    "    QA_system=np.argsort(similarity, axis=1)[:,::-1]\n",
    "    #print(QA_system)\n",
    "    for idx,row in enumerate(QA_system):\n",
    "        print(\"\\033[1m\"\"Question:\", \" \", qs[idx])\n",
    "        print( \"\\033[0m\"\"Answer:\",\" \", sents[row[0]])\n",
    "        print(\" \")\n",
    "        print(\"...............\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4  0.45 0.36 ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.31 0.31 0.31]]\n",
      "(122, 500)\n",
      "\u001b[1mQuestion:   What age group has the highest rate of severe outcomes?\n",
      "\u001b[0mAnswer:   A CDC Morbidity & Mortality Weekly Report that looked at severity of disease among COVID-19 cases in the United States by age group found that 80% of deaths were among adults 65 years and older with the highest percentage of severe outcomes occurring in people 85 years and older.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   How is COVID-19 spread?\n",
      "\u001b[0mAnswer:   Does the patient reside in an area where there has been community spread of COVID-19?\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   How many states in the U.S. have reported cases of COVID-19?\n",
      "\u001b[0mAnswer:   All 50 states have reported cases of COVID-19 to CDC.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   When did the White House launch the \"15 Days to Slow the Spread\" program?\n",
      "\u001b[0mAnswer:   CDC Recommends\n",
      "Everyone can do their part to help us respond to this emerging public health threat:\n",
      "On March 16, the White House announced a program called “15 Days to Slow the Spread,”pdf iconexternal icon which is a nationwide effort to slow the spread of COVID-19 through the implementation of social distancing at all levels of society.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What should mildly-ill patients do?\n",
      "\u001b[0mAnswer:   People who are mildly ill with COVID-19 are able to isolate at home during their illness.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What type of virus is SARS-CoV-2?\n",
      "\u001b[0mAnswer:   The SARS-CoV-2 virus is a betacoronavirus, like MERS-CoV and SARS-CoV.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What viruses are similar to the COVID-19 coronavirus?\n",
      "\u001b[0mAnswer:   COVID-19 Emergence\n",
      "COVID-19 is caused by a coronavirus.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What are the phases of a pandemic?\n",
      "\u001b[0mAnswer:   Pandemics of respiratory disease follow a certain progression outlined in a “Pandemic Intervals Framework.” Pandemics begin with an investigation phase, followed by recognition, initiation, and acceleration phases.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   At which phase does the peak of the pandemic occur?\n",
      "\u001b[0mAnswer:   The peak of illnesses occurs at the end of the acceleration phase, which is followed by a deceleration phase, during which there is a decrease in illnesses.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   People with which medical conditions have a higher rate of severe illness?\n",
      "\u001b[0mAnswer:   Older people and people with severe chronic conditions should take special precautions because they are at higher risk of developing serious COVID-19 illness.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What kind of test can diagnose COVID-19?\n",
      "\u001b[0mAnswer:   CDC developed an rRT-PCR test to diagnose COVID-19.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   In what species did the COVID-19 virus likely originate?\n",
      "\u001b[0mAnswer:   Coronaviruses are a large family of viruses that are common in people and many different species of animals, including camels, cattle, cats, and bats.\n",
      " \n",
      "...............\n",
      "\u001b[1mQuestion:   What risk factors should be considered in addition to clinical symptoms?\n",
      "\u001b[0mAnswer:   Factors to consider in addition to clinical symptoms may include:\n",
      "Does the patient have recent travel from an affected area?\n",
      " \n",
      "...............\n"
     ]
    }
   ],
   "source": [
    "# Test the system\n",
    "\n",
    "find_solutions(qs, article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Compare the answers you find with the \"ground-truth\" answers in the json file and analyze the following:\n",
    "\n",
    "- What kind of questions can be correctly answered by your system? What kind of questions CANNOT be correctly answered by your system?\n",
    "\n",
    "- Why does your system fail to locate the right answers to these questions?\n",
    "\n",
    "- How should your system be improve so that such questions can be answered?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
